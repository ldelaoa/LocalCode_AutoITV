{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b3931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "plot in line\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import rotate\n",
    "import csv\n",
    "import SimpleITK as sitk\n",
    "#from lungtumormask import mask as tumormask\n",
    "#from lungmask import mask as lungmask_fun\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    RandFlipd,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    FillHoles,\n",
    "    RemoveSmallObjects,\n",
    "    KeepLargestConnectedComponent,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensity,\n",
    "    SaveImaged,\n",
    "    CenterSpatialCropd,\n",
    "    SpatialCropd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    AsDiscrete,\n",
    "    SpatialCrop,\n",
    "    RandSpatialCropd,\n",
    "    SpatialPadd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Invertd,\n",
    "    DivisiblePadd,\n",
    "    MapTransform,\n",
    "    RandWeightedCropd,\n",
    "    ToTensord,\n",
    "    Transpose,\n",
    "    ToTensor,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet,VNet,SwinUNETR,UNETR,DynUNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric,SurfaceDiceMetric,SurfaceDistanceMetric,HausdorffDistanceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch,pad_list_data_collate\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)\n",
    "\n",
    "\n",
    "if True:\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "    print('plot in line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18000289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LookSortFiles(root_path, all_patientdir):\n",
    "    CT_fpaths = []\n",
    "    lbl_fpaths = []\n",
    "    lung_fpaths = []\n",
    "\n",
    "    for patient_path in all_patientdir:\n",
    "        ct_miss = True\n",
    "        gtv_miss = True\n",
    "        lung_miss = True\n",
    "        for root, dirs, files in os.walk(root_path + patient_path, topdown=False):\n",
    "            for f in files:\n",
    "                if True:  # 4D Data local\n",
    "                    if \"ct.nii.gz\" in f.lower() and not(\"ave\" in f.lower()):\n",
    "                        CT_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        ct_miss = False\n",
    "                    if \"_gtv\" in f.lower():\n",
    "                        lbl_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        gtv_miss = False\n",
    "                    if \"lungmask.nii.gz\" in f.lower() and not(\"ave\" in f.lower()):\n",
    "                        lung_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        lung_miss = False\n",
    "            if gtv_miss:\n",
    "                for f in files:\n",
    "                    if \"_igtv\" in f.lower():\n",
    "                        lbl_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        gtv_miss = False\n",
    "            if ct_miss and lung_miss:\n",
    "                for f in files:\n",
    "                    if \"ex_ct.nii.gz\" in f.lower() and ct_miss:\n",
    "                        CT_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        ct_miss = False\n",
    "                    if 'ex_lungmask.nii.gz' in f.lower() and lung_miss:\n",
    "                        lung_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        lung_miss = False\n",
    "            if ct_miss and lung_miss:\n",
    "                for f in files:\n",
    "                    if \"mar_ct.nii.gz\" in f.lower() and ct_miss:\n",
    "                        CT_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        ct_miss = False\n",
    "                    if 'mar_lungmask.nii.gz' in f.lower() and lung_miss:\n",
    "                        lung_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        lung_miss = False\n",
    "            if ct_miss and lung_miss:\n",
    "                for f in files:\n",
    "                    if \"ct.nii.gz\" in f.lower() and ct_miss:\n",
    "                        CT_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        ct_miss = False\n",
    "                    if 'lungmask.nii.gz' in f.lower() and lung_miss:\n",
    "                        lung_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        lung_miss = False\n",
    "            if gtv_miss and len(files) > 0:\n",
    "                CT_fpaths.pop()\n",
    "                ct_miss = True\n",
    "                lung_fpaths.pop()\n",
    "                lung_miss = True\n",
    "\n",
    "    print('ct: ', len(CT_fpaths), 'label: ', len(lbl_fpaths), 'lung: ', len(lung_fpaths))\n",
    "    if False:\n",
    "        CreateLungMasks(root_path, CT_fpaths)\n",
    "        print('Rerun the program')\n",
    "        exit(1)\n",
    "\n",
    "    CT_fpaths.sort()\n",
    "    lbl_fpaths.sort()\n",
    "    lung_fpaths.sort()\n",
    "\n",
    "    print(CT_fpaths[-1])\n",
    "    print(lbl_fpaths[-1])\n",
    "    print(lung_fpaths[-1])\n",
    "\n",
    "\n",
    "    if (len(CT_fpaths) != len(lbl_fpaths)) or (len(lbl_fpaths) != len(lung_fpaths)):\n",
    "        print('Different number of files for each structure')\n",
    "        exit(1)\n",
    "\n",
    "    return CT_fpaths, lbl_fpaths, lung_fpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aff453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309\n"
     ]
    }
   ],
   "source": [
    "##if name\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)\n",
    "num_workers = 0\n",
    "\n",
    "# root_path = '/data/p308104/Nifti_Imgs_V0/' #UMCG data on peregrine\n",
    "#root_path = '/data/p308104/MultipleBP/'\n",
    "#root_path = '/home/umcg/OneDrive/MultipleBreathingP/'\n",
    "root_path = '/home/umcg/Desktop/AutomaticITV_code/SABR1322_Nifti/'\n",
    "\n",
    "#preweight_path = '/data/p308104/weights/v9/'\n",
    "preweight_path = '/home/umcg/Desktop/AutomaticITV_code/weights/v9/'\n",
    "\n",
    "figures_path = '/home/umcg/Desktop/AutomaticITV_code/figures_folder_i/'\n",
    "\n",
    "cache = False\n",
    "lf_select = None # NOT Needed for testing\n",
    "\n",
    "SelectModel = 0 # 0 Swin  - 1 Dyn\n",
    "figures_folder_i = figures_path+'figures_SU_l3_v9/'\n",
    "pretrained_path = preweight_path + 'best_SwinUnet_V9_NBIA_Loss3.pth'\n",
    "print('LF is ', lf_select, 'Db is UMCG')\n",
    "name_run = \"NameRun\"+str(SelectModel) + \"LF\" + str(lf_select) + \"run1\"\n",
    "print(name_run)\n",
    "main(SelectModel,figures_folder_i,name_run, pretrained_path, cache, num_workers, root_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49abbe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct:  307 label:  307 lung:  307\n",
      "/home/umcg/Desktop/NBIA/NBIA_Nifti_v0/LUNG1-125/LUNG1-125_ct.nii.gz\n",
      "/home/umcg/Desktop/NBIA/NBIA_Nifti_v0/LUNG1-125/LUNG1-125_ct_GTV-1.nii.gz\n",
      "/home/umcg/Desktop/NBIA/NBIA_Nifti_v0/LUNG1-125/LUNG1-125_xBP_LungMask.nii.gz\n"
     ]
    }
   ],
   "source": [
    "##MAIN\n",
    "all_patientdir = []\n",
    "all_patientdir = os.listdir(root_path)\n",
    "all_patientdir.sort()\n",
    "print(len(all_patientdir),'in',name_run)\n",
    "\n",
    "CT_fpaths, lbl_fpaths, lung_fpaths = LookSortFiles(root_path, all_patientdir)\n",
    "\n",
    "#Create data dictionat\n",
    "data_dicts = [\n",
    "    {\"image\": image_name,\"lung\":lung_name,\"label\": label_name}\n",
    "    for image_name,lung_name,label_name in zip(CT_fpaths,lung_fpaths,lbl_fpaths)\n",
    "]\n",
    "val_files =  data_dicts[:]\n",
    "print('train val len:',0,'-',len(val_files))\n",
    "\n",
    "minmin_CT = -1024 #NBIA\n",
    "maxmax_CT = 3071 #NBIA\n",
    "\n",
    "#Create Compose functions for preprocessing of train and validation\n",
    "set_determinism(seed=0)\n",
    "image_keys = [\"image\",\"lung\",\"label\"]\n",
    "p = .5 #Data aug transform probability\n",
    "size = 96\n",
    "image_size = (size,size,size)\n",
    "pin_memory = True if num_workers > 0 else False  # Do not change\n",
    "\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=image_keys),\n",
    "        EnsureChannelFirstd(keys=image_keys),\n",
    "        Orientationd(keys=[\"image\",\"label\"], axcodes=\"RAS\"),\n",
    "        #Spacingd(keys=[\"image\",\"label\"], pixdim=(1,1,1),mode=(\"bilinear\",\"nearest\")),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=minmin_CT, a_max=maxmax_CT,b_min=0.0, b_max=1.0, clip=True,),\n",
    "        Create_sequences(keys=image_keys),\n",
    "        CropForegroundd(keys=image_keys, source_key=\"lung\",k_divisible = size),\n",
    "        ToTensord(keys=image_keys),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Check the images after the preprocessing\n",
    "if cache:  # Cache\n",
    "    #train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=num_workers)\n",
    "    #train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=num_workers)\n",
    "    val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0,\n",
    "                          num_workers=int(num_workers // 2))\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=int(num_workers // 2), pin_memory=pin_memory)\n",
    "else:\n",
    "    #train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "    #train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0)\n",
    "    val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=0)  # ,collate_fn=pad_list_data_collate)\n",
    "\n",
    "#Plot Input Volume\n",
    "#plotInputVolume(val_loader, device)\n",
    "\n",
    "# Create the model\n",
    "spatial_dims = 3\n",
    "max_epochs = 250\n",
    "in_channels = 1\n",
    "out_channels = 2  # including background\n",
    "lr = 1e-3  # 1e-4\n",
    "weight_decay = 1e-5\n",
    "T_0 = 40  # Cosine scheduler\n",
    "\n",
    "task_id = \"06\"\n",
    "deep_supr_num = 1  # when is 3 shape of outputs/labels dont match\n",
    "patch_size = image_size\n",
    "spacing = [1, 1, 1]\n",
    "kernels, strides = get_kernels_strides(patch_size, spacing)\n",
    "if SelectModel:\n",
    "    print(\"MODEL Dyn\")\n",
    "    task_id = \"06\"\n",
    "    model = DynUNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=kernels,\n",
    "        strides=strides,\n",
    "        upsample_kernel_size=strides[1:],\n",
    "        norm_name=\"instance\",\n",
    "        deep_supervision=False,  # when is 3 shape of outputs/labels dont match\n",
    "        deep_supr_num=deep_supr_num,\n",
    "    ).to(device)\n",
    "else:\n",
    "    print(\"MODEL SWIN\")\n",
    "    model = SwinUNETR(\n",
    "        image_size,\n",
    "        in_channels, out_channels,\n",
    "        use_checkpoint=True,\n",
    "        feature_size=48,\n",
    "        #spatial_dims=spatial_dims\n",
    "    ).to(device)\n",
    "\n",
    "#metrics, no definition of :\n",
    "#NO Loss Function\n",
    "#NO Optimizer\n",
    "# Load pretrained model\n",
    "if pretrained_path is not(None):\n",
    "    model.load_state_dict(torch.load(pretrained_path, map_location=torch.device(device)))\n",
    "    print('Using pretrained weights!')\n",
    "all_metrics = test(figures_folder_i ,image_size,model, val_loader,device,val_files)\n",
    "\n",
    "\n",
    "#Save csv of metrics\n",
    "if True:\n",
    "    f= open(figures_folder_i+str(SelectModel)+'res_UMCGx5_ValidationSET_JusHaus.csv','w', encoding='UTF8')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Patient','Dice V','Dice P','Sdice V','SDice P','HausD V','HausD P','Diff'])\n",
    "    writer.writerows(all_metrics)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcbb35a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val len: 50\n"
     ]
    }
   ],
   "source": [
    "#Create data dictionat\n",
    "data_dicts = [\n",
    "    {\"image\": image_name,\"label\": label_name,\"lung\":lung_name}\n",
    "    for image_name,label_name,lung_name in zip(CT_fpaths,lbl_fpaths,lung_fpaths)\n",
    "]\n",
    "val_files = data_dicts[-50:]\n",
    "print('train val len:',len(val_files))\n",
    "\n",
    "minmin_CT = -1024 #NBIA\n",
    "maxmax_CT = 3071 #NBIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2889b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to transpose lung mask\n",
    "class Create_sequences(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__(keys)\n",
    "        \n",
    "        print(f\"keys to transpose: {self.keys}\")\n",
    "\n",
    "         \n",
    "    def __call__(self, dictionary):\n",
    "        dictionary = dict(dictionary)\n",
    "        for key in self.keys:\n",
    "            data = dictionary[key]\n",
    "            if key == 'lung':\n",
    "                data = np.transpose(data, (0,2,3,1))\n",
    "                data = rotate(data,270,axes=(1,2),reshape=False)\n",
    "                data = np.flip(data,1)\n",
    "                data[data==2] = int(1)\n",
    "                data[data!=1] = int(0)\n",
    "            dictionary[key] = data\n",
    "            \n",
    "        return dictionary        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8831609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys to transpose: ('image', 'label', 'lung')\n"
     ]
    }
   ],
   "source": [
    "#Create Compose functions for preprocessing of train and validation\n",
    "#set_determinism(seed=0)\n",
    "image_keys = [\"image\",\"label\",\"lung\"]\n",
    "p = .5 #Data aug transform probability\n",
    "size = 96\n",
    "image_size = (size,size,size)\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=image_keys),\n",
    "        EnsureChannelFirstd(keys=image_keys),\n",
    "        Orientationd(keys=[\"image\",\"label\"], axcodes=\"RAS\"),\n",
    "        #Spacingd(keys=[\"image\",\"label\"], pixdim=(1,1,1),mode=(\"bilinear\",\"nearest\")),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=minmin_CT, a_max=maxmax_CT,b_min=0.0, b_max=1.0, clip=True,),\n",
    "        Create_sequences(keys=image_keys),\n",
    "        CropForegroundd(keys=image_keys, source_key=\"lung\",k_divisible = size),\n",
    "        ToTensord(keys=image_keys),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed9024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the images after the preprocessing\n",
    "if False:\n",
    "    check_ds =Dataset(data=val_files, transform=val_transforms)\n",
    "    check_loader = DataLoader(check_ds, batch_size=1,num_workers=0)\n",
    "    if True:\n",
    "        count = 1\n",
    "        for batch_data in check_loader:\n",
    "            #batch_data = first(check_loader)\n",
    "            image,lung, label = (batch_data[\"image\"][0][0],batch_data[\"lung\"][0][0],batch_data[\"label\"][0][0])\n",
    "            print(f\"px info:{count },image shape: {image.shape},lung shape: {lung.shape}, label shape: {label.shape}\")\n",
    "            count+=1\n",
    "            for i in range(label.shape[2]):\n",
    "                if torch.sum(label[:,:,i])>0:\n",
    "                    plt.subplot(1,3,1),plt.imshow(image[:,:,i]),plt.axis('off')\n",
    "                    plt.subplot(1,3,2),plt.imshow(label[:,:,i]+lung[:,:,i]),plt.axis('off')\n",
    "                    plt.subplot(1,3,3),plt.imshow(label[:,:,i]+image[:,:,i]),plt.axis('off')\n",
    "                    plt.tight_layout(),plt.show()\n",
    "                    break\n",
    "            if count>10:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e57cceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=0)#,collate_fn=pad_list_data_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff2ce219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model\n",
    "spatial_dims = 3\n",
    "max_epochs = 100\n",
    "in_channels = 1\n",
    "out_channels=2 #including background\n",
    "model = SwinUNETR(\n",
    "    image_size, \n",
    "    in_channels, out_channels, \n",
    "    use_checkpoint=True, \n",
    "    feature_size=24,\n",
    "    #spatial_dims=spatial_dims\n",
    ").to(device)\n",
    "\n",
    "#metrics\n",
    "loss_function = DiceLoss(to_onehot_y=True, sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "surfDice_metric_1Class = SurfaceDiceMetric([5],include_background=False)\n",
    "hausdorff_metric = HausdorffDistanceMetric(include_background=True, reduction=\"mean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39e715ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained weights!\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model\n",
    "pretrained_path = '/home/umcg/Desktop/AutomaticITV_code/weights/v8(andOlder)/best_m_MONAI_V3_UMCGWeightsretrainedWithUMCGdata_X2RetrainedwithAITVdata.pth'\n",
    "#pretrained_path = '/data/p308104/MultipleBP/best_m_MONAI_V3_UMCGWeightsretrainedWithUMCGdata_X2RetrainedwithAITVdata.pth'\n",
    "if pretrained_path is not(None):\n",
    "    model.load_state_dict(torch.load(pretrained_path, map_location=torch.device(device)))\n",
    "\n",
    "    #weight = torch.load(pretrained_path, map_location=torch.device(device))\n",
    "    #model.load_from(weights=weight)\n",
    "    print('Using pretrained weights!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "008812da",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_transforms = Compose(\n",
    "    [\n",
    "        EnsureType(),\n",
    "        AsDiscrete(argmax=True,to_onehot=out_channels, threshold=.5),\n",
    "        FillHoles(applied_labels=1, connectivity=0),\n",
    "        RemoveSmallObjects(min_size=5, connectivity=3, independent_channels=True),\n",
    "        #KeepLargestConnectedComponent(applied_labels=None,is_onehot=True,connectivity=3, num_components=3),\n",
    "   ]\n",
    ")\n",
    "\n",
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True,threshold=0.5), \n",
    "                     ScaleIntensity(minv=0.0, maxv=1.0)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(threshold=0.5)],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d85fa2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute metric for current iteration\n",
    "#Batch x Channel x Height x Width - [B,C,H,W] - 1, 384, 288, 192\n",
    "#Channel is number of classes\n",
    "def surfDiceFun_1Class(val_labels,postImg_monai):\n",
    "    ylabe_BCHW_neg = val_labels[0].cpu().numpy()\n",
    "    ylabe_BCHW_neg = ylabe_BCHW_neg*-1+1\n",
    "    ylabe_BCHW_pos = val_labels[0].cpu().numpy()\n",
    "    ylabe_BCHW = np.concatenate((ylabe_BCHW_neg, ylabe_BCHW_pos),0)\n",
    "    transpose_monai = Compose([Transpose([3, 0, 1, 2])])\n",
    "    ylabe_BCHW = transpose_monai(ylabe_BCHW)\n",
    "    ypred_BCHW = postImg_monai[0].permute(3, 0, 1, 2)\n",
    "    \n",
    "    #print(ypred_BCHW.shape,ylabe_BCHW.shape)\n",
    "    list_surf=[]\n",
    "    for i in range(ypred_BCHW.shape[0]-4):\n",
    "        if  np.sum(ylabe_BCHW[i:i+2,1,:,:])>0:# or np.sum(ypred_BCHW[i:i+2,0,:,:])>0:\n",
    "            surfDice_metric_1Class(y_pred=ypred_BCHW[i:i+2,:,:,:], y=ylabe_BCHW[i:i+2,0:,:,:])\n",
    "            list_surf.append(surfDice_metric_1Class.aggregate().item())\n",
    "            #print(list_surf[-1])\n",
    "            surfDice_metric_1Class.reset()\n",
    "    return np.mean(list_surf)\n",
    "#hausdorff_metric(y_pred=postImg_monai, y=val_labels)\n",
    "#print('hausdorff monai    :',hausdorff_metric.aggregate().item())\n",
    "#hausdorff_metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829065ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "209528fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umcg/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUNG1-262 v0/LUNG1-262/LUNG1-262\n",
      "0.0 1.0 0.0 1.0\n",
      "Scores vanilla: 0.25204935669898987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umcg/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/metrics/surface_dice.py:222: UserWarning: the ground truth of class 0 is all 0, this may result in nan/inf distance.\n",
      "  warnings.warn(f\"the ground truth of class {c} is all 0, this may result in nan/inf distance.\")\n",
      "/home/umcg/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/metrics/surface_dice.py:224: UserWarning: the prediction of class 0 is all 0, this may result in nan/inf distance.\n",
      "  warnings.warn(f\"the prediction of class {c} is all 0, this may result in nan/inf distance.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SurfFice vanilla 1 class: 0.16273399482508333\n",
      "Scores monai    : 0.15301287174224854\n",
      "SurfFice monai 1 class: 0.16273399482508333\n",
      "LUNG1-263 v0/LUNG1-263/LUNG1-263\n",
      "0.0 1.0 0.0 1.0\n",
      "Scores vanilla: 0.0\n",
      "SurfFice vanilla 1 class: 0.0\n",
      "Scores monai    : 0.0\n",
      "SurfFice monai 1 class: 0.0\n",
      "LUNG1-264 v0/LUNG1-264/LUNG1-264\n",
      "0.0 1.0 0.0 1.0\n",
      "Scores vanilla: 0.7889872789382935\n",
      "SurfFice vanilla 1 class: 0.7575334875790335\n",
      "Scores monai    : 0.5932325720787048\n",
      "SurfFice monai 1 class: 0.7575334875790335\n",
      "LUNG1-265 v0/LUNG1-265/LUNG1-265\n",
      "0.0 1.0 0.0 1.0\n",
      "Scores vanilla: 0.8027952313423157\n",
      "SurfFice vanilla 1 class: 0.8625119146670213\n",
      "Scores monai    : 0.6771513223648071\n",
      "SurfFice monai 1 class: 0.8625119146670213\n",
      "LUNG1-266 v0/LUNG1-266/LUNG1-266\n",
      "0.0 1.0 0.0 1.0\n",
      "Scores vanilla: 0.285881906747818\n",
      "SurfFice vanilla 1 class: 0.3477842579763954\n",
      "Scores monai    : 0.17404808104038239\n",
      "SurfFice monai 1 class: 0.3477842579763954\n",
      "LUNG1-267 v0/LUNG1-267/LUNG1-267\n",
      "0.0 1.0 0.0 1.0\n",
      "Scores vanilla: 0.1091567873954773\n",
      "SurfFice vanilla 1 class: 0.180336569102384\n",
      "Scores monai    : 0.07424899190664291\n",
      "SurfFice monai 1 class: 0.180336569102384\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m figs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m val_data \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[1;32m     12\u001b[0m         val_inputs, val_labels \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     13\u001b[0m             val_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     14\u001b[0m             val_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),)\n\u001b[1;32m     15\u001b[0m         roi_size \u001b[38;5;241m=\u001b[39m image_size\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/data/dataset.py:105\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# dataset[[1, 3, 4]]\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Subset(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, indices\u001b[38;5;241m=\u001b[39mindex)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/data/dataset.py:91\u001b[0m, in \u001b[0;36mDataset._transform\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03mFetch single data item from `self.data`.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m data_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index]\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_i\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m data_i\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/transforms/transform.py:91\u001b[0m, in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m map_items:\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# if in debug mode, don't swallow exception so that the breakpoint\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# appears where the exception was raised.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m MONAIEnvVars\u001b[38;5;241m.\u001b[39mdebug():\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/transforms/transform.py:55\u001b[0m, in \u001b[0;36m_apply_transform\u001b[0;34m(transform, parameters, unpack_parameters)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(parameters, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m unpack_parameters:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mparameters)\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/transforms/compose.py:173\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_):\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m--> 173\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m \u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m input_\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/transforms/transform.py:91\u001b[0m, in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m map_items:\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# if in debug mode, don't swallow exception so that the breakpoint\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# appears where the exception was raised.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m MONAIEnvVars\u001b[38;5;241m.\u001b[39mdebug():\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/transforms/transform.py:55\u001b[0m, in \u001b[0;36m_apply_transform\u001b[0;34m(transform, parameters, unpack_parameters)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(parameters, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m unpack_parameters:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mparameters)\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/transforms/intensity/dictionary.py:784\u001b[0m, in \u001b[0;36mScaleIntensityRanged.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    782\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(data)\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_iterator(d):\n\u001b[0;32m--> 784\u001b[0m     d[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/transforms/intensity/array.py:785\u001b[0m, in \u001b[0;36mScaleIntensityRange.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma_min\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma_min \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_min\n\u001b[0;32m--> 785\u001b[0m img \u001b[38;5;241m=\u001b[39m (\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma_min\u001b[49m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma_max \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma_min)\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_min \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_max \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    787\u001b[0m     img \u001b[38;5;241m=\u001b[39m img \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_max \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_min) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_min\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/data/meta_tensor.py:249\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 249\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# we might have 1 or multiple outputs. Might be MetaTensor, might be something\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# else (e.g., `__repr__` returns a string).\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Convert to list (if necessary), process, and at end remove list if one was added.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(torch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_types\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m ):\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;66;03m# for torch.max(torch.tensor(1.0), dim=0), the return type is named-tuple like\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/torch/_tensor.py:1121\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1121\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1123\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Testing the model\n",
    "count=0\n",
    "nr_images=8\n",
    "figsize = (18, 12)\n",
    "#figures_folder_i = '/data/p308104/MultipleBP_Res/' #Peregrine\n",
    "figures_folder_i ='/home/umcg/Desktop/AutomaticITV_code/figures_folder_UMCG/' #Local\n",
    "all_metrics = []\n",
    "model.eval()\n",
    "figs = False\n",
    "with torch.no_grad():\n",
    "    for val_data in val_loader:\n",
    "        val_inputs, val_labels = (\n",
    "            val_data[\"image\"].to(device),\n",
    "            val_data[\"label\"].to(device),)\n",
    "        roi_size = image_size\n",
    "        sw_batch_size = 1\n",
    "        val_outputs = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model)\n",
    "        \n",
    "        postImg_monai = [post_transforms(i) for i in decollate_batch(val_outputs)]\n",
    "        px = val_data[\"image\"].meta[\"filename_or_obj\"][0].split('/')[-2]\n",
    "        newGTV_name = val_data[\"image\"].meta[\"filename_or_obj\"][0][:-9]+'aGTV.nii.gz'\n",
    "        #bp = val_data[\"image\"].meta[\"filename_or_obj\"][0].split('%')[-2][-2:]\n",
    "        bp = val_data[\"image\"].meta[\"filename_or_obj\"][0].split('_')[-2][:]\n",
    "        print(px,bp)\n",
    "\n",
    "        if figs: #AXIAL\n",
    "            slice_indices = []   \n",
    "            for i in range(val_inputs.shape[4]):\n",
    "                if np.sum(val_outputs[0][0,:,:,i])>0:\n",
    "                    slice_indices.append(i)\n",
    "            if len(slice_indices) <nr_images:\n",
    "                slice_indices.append(random.sample(range(1, val_inputs.shape[4]),nr_images-len(slice_indices))[0])\n",
    "            else:\n",
    "                slice_indices = random.sample(slice_indices, k=nr_images)\n",
    "            instance = random.randint(0, val_inputs.shape[0] - 1)\n",
    "            j = 1\n",
    "            for i, idx in enumerate(slice_indices):\n",
    "                j=1+i\n",
    "                fig = plt.figure('Instance = {}'.format(instance), figsize=figsize)\n",
    "                plt.subplot(3, nr_images, j),plt.title('AXIAL CT ({})'.format(idx)),plt.imshow(val_inputs.cpu().numpy()[instance, 0, :, :, idx], cmap='gray', vmin=0, vmax=1),plt.axis('off')\n",
    "                plt.subplot(3, nr_images, nr_images+j),plt.title('Prediction ({})'.format(idx)),plt.imshow(val_inputs.cpu().numpy()[instance, 0, :, :, idx]+val_outputs[0].detach().cpu()[instance, :, :, idx]),plt.axis('off')\n",
    "                plt.subplot(3, nr_images, 2*nr_images+j),plt.title('postImg Monai ({})'.format(idx)),plt.imshow(val_inputs.cpu().numpy()[instance, 0, :, :, idx]+postImg_monai[0].detach().cpu()[instance, :, :, idx]),plt.axis('off')\n",
    "            plt.tight_layout(),plt.show()\n",
    "            if not os.path.exists(os.path.join(figures_folder_i,px)):\n",
    "                os.makedirs(os.path.join(figures_folder_i,px)) \n",
    "            plt.savefig(os.path.join(figures_folder_i,px,bp+'AXIAL final_{}.png'.format(px)))\n",
    "        if figs: #SAGITAL\n",
    "            slice_indices = []   \n",
    "            for i in range(val_inputs.shape[3]):\n",
    "                if np.sum(val_outputs[0][0,:,i,:])>0:\n",
    "                    slice_indices.append(i)\n",
    "            if len(slice_indices) <nr_images:\n",
    "                slice_indices.append(random.sample(range(1, val_inputs.shape[3]),nr_images-len(slice_indices))[0])\n",
    "            else:\n",
    "                slice_indices = random.sample(slice_indices, k=nr_images)\n",
    "            instance = random.randint(0, val_inputs.shape[0] - 1)\n",
    "            j = 1\n",
    "            for i, idx in enumerate(slice_indices):\n",
    "                j=1+i\n",
    "                fig = plt.figure('Instance = {}'.format(instance), figsize=figsize)\n",
    "                plt.subplot(3, nr_images, j),plt.title('SAGITAL CT ({})'.format(idx)),plt.imshow(val_inputs.cpu().numpy()[instance, 0, :, idx,:], cmap='gray', vmin=0, vmax=1),plt.axis('off')\n",
    "                plt.subplot(3, nr_images, nr_images+j),plt.title('Prediction ({})'.format(idx)),plt.imshow(val_inputs.cpu().numpy()[instance, 0, :, idx,:]+val_outputs[0].detach().cpu()[instance, :,idx,:]),plt.axis('off')\n",
    "                plt.subplot(3, nr_images, 2*nr_images+j),plt.title('postImg Monai ({})'.format(idx)),plt.imshow(val_inputs.cpu().numpy()[instance, 0, :, idx,:]+postImg_monai[0].detach().cpu()[instance, :,idx,:]),plt.axis('off')\n",
    "            plt.tight_layout(),plt.show()\n",
    "            if not os.path.exists(os.path.join(figures_folder_i,px)):\n",
    "                os.makedirs(os.path.join(figures_folder_i,px)) \n",
    "            plt.savefig(os.path.join(figures_folder_i,px,bp+'SAGITAL final_{}.png'.format(px)))\n",
    "        if figs: #CORONAL\n",
    "            slice_indices = []   \n",
    "            for i in range(val_inputs.shape[2]):\n",
    "                if np.sum(val_outputs[0][0,i,:,:])>0:\n",
    "                    slice_indices.append(i)\n",
    "            if len(slice_indices) <nr_images:\n",
    "                slice_indices.append(random.sample(range(1, val_inputs.shape[2]),nr_images-len(slice_indices))[0])\n",
    "            else:\n",
    "                slice_indices = random.sample(slice_indices, k=nr_images)\n",
    "            instance = random.randint(0, val_inputs.shape[0] - 1)\n",
    "            j = 1\n",
    "            for i, idx in enumerate(slice_indices):\n",
    "                j=1+i\n",
    "                fig = plt.figure('Instance = {}'.format(instance), figsize=figsize)\n",
    "                plt.subplot(3, nr_images, j),plt.title('CORONAL CT ({})'.format(idx)),plt.imshow(val_inputs.cpu().numpy()[instance, 0, idx,:,:], cmap='gray', vmin=0, vmax=1),plt.axis('off')\n",
    "                plt.subplot(3, nr_images, nr_images+j),plt.title('Prediction ({})'.format(idx)),plt.imshow(val_inputs.cpu().numpy()[instance, 0, idx,:,:]+val_outputs[0].detach().cpu()[instance,idx,:,:]),plt.axis('off')\n",
    "                plt.subplot(3, nr_images, 2*nr_images+j),plt.title('postImg Monai ({})'.format(idx)),plt.imshow(val_inputs.cpu().numpy()[instance, 0,idx,:,:]+postImg_monai[0].detach().cpu()[instance,idx,:,:]),plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            if not os.path.exists(os.path.join(figures_folder_i,px)):\n",
    "                os.makedirs(os.path.join(figures_folder_i,px)) \n",
    "            plt.savefig(os.path.join(figures_folder_i,px,bp+'CORONAL final_{}.png'.format(px)))\n",
    "\n",
    "        \n",
    "        val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "        val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "\n",
    "        print(\n",
    "            np.min(val_outputs[0]),\n",
    "            np.max(val_outputs[0]),\n",
    "            np.min(val_labels[0]),\n",
    "            np.max(val_labels[0]),\n",
    "        )\n",
    "        \n",
    "        sum_labels = np.sum(val_labels[0])\n",
    "\n",
    "        sum_outputs = np.sum(val_outputs[0])\n",
    "\n",
    "        dif = sum_labels-sum_outputs\n",
    "        \n",
    "        \n",
    "        #compute metric for current iteration\n",
    "        dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "        dice0 = dice_metric.aggregate().item()\n",
    "        print('Scores vanilla:',dice0)\n",
    "        dice_metric.reset()\n",
    "\n",
    "        sdice0 = surfDiceFun_1Class(val_labels,val_outputs)\n",
    "        print('SurfFice vanilla 1 class:',sdice0)\n",
    "        if True:\n",
    "            dice_metric(y_pred=postImg_monai[0][1:2,:,:,:], y=val_labels[0])\n",
    "            dice1 = dice_metric.aggregate().item()\n",
    "            print('Scores monai    :',dice1)\n",
    "            dice_metric.reset()\n",
    "            sdice1 = surfDiceFun_1Class(val_labels,postImg_monai)\n",
    "            print('SurfFice monai 1 class:',sdice1)\n",
    "            \n",
    "        all_metrics.append([val_files[count]['label'].split('/')[-2],dice0,dice1,sdice0,sdice1])\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae07444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a7bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52e7d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
