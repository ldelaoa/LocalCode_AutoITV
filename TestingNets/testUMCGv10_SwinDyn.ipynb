{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f2bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import rotate\n",
    "import csv\n",
    "import SimpleITK as sitk\n",
    "#from lungtumormask import mask as tumormask\n",
    "from lungmask import mask as lungmask_fun\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import dilation,ball,erosion,remove_small_objects\n",
    "\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    ResizeWithPadOrCrop,\n",
    "    RandFlipd,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    FillHoles,\n",
    "    RemoveSmallObjects,\n",
    "    KeepLargestConnectedComponent,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    CenterSpatialCropd,\n",
    "    SpatialCropd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    AsDiscrete,\n",
    "    SpatialCrop,\n",
    "    RandSpatialCropd,\n",
    "    SpatialPadd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Invertd,\n",
    "    DivisiblePadd,\n",
    "    MapTransform,\n",
    "    RandWeightedCropd,\n",
    "    ToTensord,\n",
    "    Transpose,\n",
    "    ScaleIntensity,\n",
    "    \n",
    ")\n",
    "from monai.networks.nets import UNet,VNet,SwinUNETR,UNETR,DynUNet\n",
    "from monai.metrics import DiceMetric,SurfaceDiceMetric,HausdorffDistanceMetric,compute_surface_dice\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch,pad_list_data_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b3931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "plot in line\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)\n",
    "\n",
    "if True:\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "    print('plot in line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9358167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to transpose lung mask\n",
    "class Create_sequences(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__(keys)\n",
    "        print(f\"keys to transpose: {self.keys}\")\n",
    "\n",
    "    def __call__(self, dictionary):\n",
    "        dictionary = dict(dictionary)\n",
    "        for key in self.keys:\n",
    "            data = dictionary[key]\n",
    "            if key == 'lung':\n",
    "                data = np.transpose(data, (0, 2, 3, 1))\n",
    "                data = rotate(data, 270, axes=(1, 2), reshape=False)\n",
    "                data = np.flip(data, 1)\n",
    "                data[data == 2] = int(1)\n",
    "                data[data != 1] = int(0)\n",
    "            dictionary[key] = data\n",
    "\n",
    "        return dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c0eeab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernels_strides(patch_size, spacing):\n",
    "    sizes, spacings = patch_size, spacing\n",
    "    input_size = sizes\n",
    "    strides, kernels = [], []\n",
    "    while True:\n",
    "        spacing_ratio = [sp / min(spacings) for sp in spacings]\n",
    "        stride = [\n",
    "            2 if ratio <= 2 and size >= 8 else 1\n",
    "            for (ratio, size) in zip(spacing_ratio, sizes)\n",
    "        ]\n",
    "        kernel = [3 if ratio <= 2 else 1 for ratio in spacing_ratio]\n",
    "        if all(s == 1 for s in stride):\n",
    "            break\n",
    "        for idx, (i, j) in enumerate(zip(sizes, stride)):\n",
    "            if i % j != 0:\n",
    "                raise ValueError(\n",
    "                    f\"Patch size is not supported, please try to modify the size {input_size[idx]} in the spatial dimension {idx}.\"\n",
    "                )\n",
    "        sizes = [i / j for i, j in zip(sizes, stride)]\n",
    "        spacings = [i * j for i, j in zip(spacings, stride)]\n",
    "        kernels.append(kernel)\n",
    "        strides.append(stride)\n",
    "\n",
    "    strides.insert(0, len(spacings) * [1])\n",
    "    kernels.append(len(spacings) * [3])\n",
    "    return kernels, strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18000289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LookSortFiles(root_path, all_patientdir):\n",
    "    CT_fpaths = []\n",
    "    lbl_fpaths = []\n",
    "    lung_fpaths = []\n",
    "\n",
    "    for patient_path in all_patientdir:\n",
    "        ct_miss = True\n",
    "        gtv_miss = True\n",
    "        lung_miss = True\n",
    "        for root, dirs, files in os.walk(root_path + patient_path, topdown=False):\n",
    "            for f in files:\n",
    "                if True:  # 4D Data local\n",
    "                    if \"ct.nii.gz\" in f.lower() and not(\"ave\" in f.lower()):\n",
    "                        CT_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        ct_miss = False\n",
    "                    if \"_gtv\" in f.lower():\n",
    "                        lbl_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        gtv_miss = False\n",
    "                    if \"lungmask.nii.gz\" in f.lower() and not(\"ave\" in f.lower()):\n",
    "                        lung_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        lung_miss = False\n",
    "            if gtv_miss:\n",
    "                for f in files:\n",
    "                    if \"_igtv\" in f.lower():\n",
    "                        lbl_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        gtv_miss = False\n",
    "            if ct_miss and lung_miss:\n",
    "                for f in files:\n",
    "                    if \"ex_ct.nii.gz\" in f.lower() and ct_miss:\n",
    "                        CT_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        ct_miss = False\n",
    "                    if 'ex_lungmask.nii.gz' in f.lower() and lung_miss:\n",
    "                        lung_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        lung_miss = False\n",
    "            if ct_miss and lung_miss:\n",
    "                for f in files:\n",
    "                    if \"mar_ct.nii.gz\" in f.lower() and ct_miss:\n",
    "                        CT_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        ct_miss = False\n",
    "                    if 'mar_lungmask.nii.gz' in f.lower() and lung_miss:\n",
    "                        lung_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        lung_miss = False\n",
    "            if ct_miss and lung_miss:\n",
    "                for f in files:\n",
    "                    if \"ct.nii.gz\" in f.lower() and ct_miss:\n",
    "                        CT_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        ct_miss = False\n",
    "                    if 'lungmask.nii.gz' in f.lower() and lung_miss:\n",
    "                        lung_fpaths.append(os.path.join(root_path, patient_path, f))\n",
    "                        lung_miss = False\n",
    "            if gtv_miss and len(files) > 0:\n",
    "                CT_fpaths.pop()\n",
    "                ct_miss = True\n",
    "                lung_fpaths.pop()\n",
    "                lung_miss = True\n",
    "\n",
    "    print('ct: ', len(CT_fpaths), 'label: ', len(lbl_fpaths), 'lung: ', len(lung_fpaths))\n",
    "    if False:\n",
    "        CreateLungMasks(root_path, CT_fpaths)\n",
    "        print('Rerun the program')\n",
    "        exit(1)\n",
    "\n",
    "    CT_fpaths.sort()\n",
    "    lbl_fpaths.sort()\n",
    "    lung_fpaths.sort()\n",
    "\n",
    "    print(CT_fpaths[-1])\n",
    "    print(lbl_fpaths[-1])\n",
    "    print(lung_fpaths[-1])\n",
    "\n",
    "\n",
    "    if (len(CT_fpaths) != len(lbl_fpaths)) or (len(lbl_fpaths) != len(lung_fpaths)):\n",
    "        print('Different number of files for each structure')\n",
    "        exit(1)\n",
    "\n",
    "    return CT_fpaths, lbl_fpaths, lung_fpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aff453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "TestRun1LFNonerun1\n"
     ]
    }
   ],
   "source": [
    "##if name\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)\n",
    "num_workers = 0\n",
    "\n",
    "# root_path = '/data/p308104/Nifti_Imgs_V0/' #UMCG data on peregrine\n",
    "#root_path = '/data/p308104/MultipleBP/'\n",
    "#root_path = '/home/umcg/OneDrive/MultipleBreathingP/'\n",
    "root_path = '/home/umcg/Desktop/AutomaticITV_code/SABR1322_Nifti/'\n",
    "\n",
    "#preweight_path = '/data/p308104/weights/v9/'\n",
    "preweight_path = '/home/umcg/Desktop/AutomaticITV_code/weights/v10/'\n",
    "pretrained_path_Swin = preweight_path + 'best_SwinUnet_V10_UMCG_Loss3.pth'\n",
    "pretrained_path_Dyn = preweight_path + 'best_DynUnet_V10_UMCG_Loss3.pth'\n",
    "    \n",
    "\n",
    "figures_path = '/home/umcg/Desktop/AutomaticITV_code/figures_folder_i/'\n",
    "\n",
    "cache = False\n",
    "lf_select = None # NOT Needed for testing\n",
    "\n",
    "SelectModel = 1  # 0 Swin  - 1 Dyn\n",
    "figures_folder_i = figures_path+'figures_DynU_v10'\n",
    "pretrained_path = preweight_path + 'best_DynUnet_V10_UMCG_Loss3.pth'\n",
    "name_run = \"TestRun\" + str(SelectModel) + \"LF\" + str(lf_select) + \"run1\"\n",
    "print(name_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "058ba1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 in TestRun1LFNonerun1\n",
      "ct:  63 label:  63 lung:  63\n",
      "/home/umcg/Desktop/AutomaticITV_code/SABR1322_Nifti/9490514/9490514_4D thorax 2.0  2.0  Br38  3  50% iMAR_ct.nii.gz\n",
      "/home/umcg/Desktop/AutomaticITV_code/SABR1322_Nifti/9490514/9490514_rtstruct_GTV.nii.gz\n",
      "/home/umcg/Desktop/AutomaticITV_code/SABR1322_Nifti/9490514/9490514_4D thorax 2.0  2.0  Br38  3  50% iMAR_LungMask.nii.gz\n",
      "train val len: 0 - 63\n",
      "keys to transpose: ('image', 'lung', 'label')\n"
     ]
    }
   ],
   "source": [
    "##MAIN\n",
    "all_patientdir = []\n",
    "all_patientdir = os.listdir(root_path)\n",
    "all_patientdir.sort()\n",
    "print(len(all_patientdir),'in',name_run)\n",
    "\n",
    "CT_fpaths, lbl_fpaths, lung_fpaths = LookSortFiles(root_path, all_patientdir)\n",
    "    \n",
    "#Create data dictionat\n",
    "data_dicts = [\n",
    "    {\"image\": image_name,\"lung\":lung_name,\"label\": label_name}\n",
    "    for image_name,lung_name,label_name in zip(CT_fpaths,lung_fpaths,lbl_fpaths)\n",
    "]\n",
    "train_files, val_files = [], data_dicts[:]\n",
    "print('train val len:',len(train_files),'-',len(val_files))\n",
    "\n",
    "# HU are -1000 air , 0 water , usually normal tissue are around 0, top values should be around 100, bones are around 1000\n",
    "minmin_CT = -1024\n",
    "maxmax_CT = 200 \n",
    "\n",
    "#Create Compose functions for preprocessing of train and validation\n",
    "set_determinism(seed=0)\n",
    "image_keys = [\"image\",\"lung\",\"label\"]\n",
    "p = .5 #Data aug transform probability\n",
    "size = 96\n",
    "image_size = (size,size,size)\n",
    "pin_memory = True if num_workers > 0 else False  # Do not change\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=image_keys),\n",
    "        EnsureChannelFirstd(keys=image_keys),\n",
    "        Orientationd(keys=[\"image\",\"label\"], axcodes=\"RAS\"),\n",
    "        #Spacingd(keys=[\"image\",\"label\"], pixdim=(1,1,1),mode=(\"bilinear\",\"nearest\")),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=minmin_CT, a_max=maxmax_CT,b_min=0.0, b_max=1.0, clip=True,),\n",
    "        Create_sequences(keys=image_keys),\n",
    "        CropForegroundd(keys=image_keys, source_key=\"lung\",k_divisible = size),\n",
    "        \n",
    "        ToTensord(keys=image_keys),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Check the images after the preprocessing\n",
    "if cache:  # Cache\n",
    "    #train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=num_workers)\n",
    "    #train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=num_workers)\n",
    "    val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0,\n",
    "                          num_workers=int(num_workers // 2))\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=int(num_workers // 2), pin_memory=pin_memory)\n",
    "else:\n",
    "    #train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "    #train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0)\n",
    "    val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=0)  # ,collate_fn=pad_list_data_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e70426",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Check the images after the preprocessing\n",
    "if False:\n",
    "    figsize = (18, 9)\n",
    "    check_ds =Dataset(data=val_files, transform=val_transforms)\n",
    "    check_loader = DataLoader(check_ds, batch_size=1,num_workers=0)\n",
    "    if True:\n",
    "        count = 1\n",
    "        for batch_data in check_loader:\n",
    "            #batch_data = first(check_loader)\n",
    "            image,lung, label = (batch_data[\"image\"][0][0],batch_data[\"lung\"][0][0],batch_data[\"label\"][0][0])\n",
    "            print(f\"px info:{count },image shape: {image.shape},lung shape: {lung.shape}, label shape: {label.shape}\")\n",
    "            count+=1\n",
    "            for i in range(label.shape[2]):\n",
    "                if torch.sum(label[:,:,i])>0:\n",
    "                    fig = plt.figure('Instance = {}'.format(0), figsize=figsize)\n",
    "                    plt.subplot(1,2,1),plt.imshow(np.rot90(image[:,:,i]),cmap='gray'),plt.axis('off')\n",
    "                    plt.subplot(1,2,2),plt.imshow(np.rot90(image[:,:,i]),cmap='gray'),plt.axis('off')\n",
    "                    plt.contour(np.rot90(lung[:, :,i]),colors='yellow')\n",
    "                    plt.contour(np.rot90(label[:,:,i]),colors='red')\n",
    "                    plt.tight_layout(),plt.show()\n",
    "                    break\n",
    "            if count>3:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fef49d7",
   "metadata": {},
   "source": [
    "MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49abbe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL SwinDyn\n",
      "Using Swin pretrained weights!\n",
      "Using Dyn pretrained weights!\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "spatial_dims = 3\n",
    "max_epochs = 250\n",
    "in_channels = 1\n",
    "out_channels = 2  # including background\n",
    "lr = 1e-3  # 1e-4\n",
    "weight_decay = 1e-5\n",
    "T_0 = 40  # Cosine scheduler\n",
    "\n",
    "task_id = \"06\"\n",
    "deep_supr_num = 1  # when is 3 shape of outputs/labels dont match\n",
    "patch_size = image_size\n",
    "spacing = [1, 1, 1]\n",
    "kernels, strides = get_kernels_strides(patch_size, spacing)\n",
    "\n",
    "print(\"MODEL SwinDyn\")\n",
    "modelSwin = SwinUNETR(\n",
    "    image_size,\n",
    "    in_channels, out_channels,\n",
    "    use_checkpoint=True,\n",
    "    feature_size=48,\n",
    "    # spatial_dims=spatial_dims\n",
    ").to(device)\n",
    "task_id = \"06\"\n",
    "modelDyn = DynUNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=in_channels,\n",
    "    out_channels=out_channels,\n",
    "    kernel_size=kernels,\n",
    "    strides=strides,\n",
    "    upsample_kernel_size=strides[1:],\n",
    "    norm_name=\"instance\",\n",
    "    deep_supervision=False,  # when is 3 shape of outputs/labels dont match\n",
    "    deep_supr_num=deep_supr_num,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "#metrics, no definition of :\n",
    "#NO Loss Function\n",
    "#NO Optimizer\n",
    "# Load pretrained model\n",
    "if pretrained_path_Swin is not(None):\n",
    "        modelSwin.load_state_dict(torch.load(pretrained_path_Swin, map_location=torch.device(device)))\n",
    "        print('Using Swin pretrained weights!')\n",
    "if pretrained_path_Dyn is not(None):\n",
    "    modelDyn.load_state_dict(torch.load(pretrained_path_Dyn, map_location=torch.device(device)))\n",
    "    print('Using Dyn pretrained weights!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcbb35a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "Px:  0070683\n",
      "num de blobs in label:  1\n",
      "label bbox  (163, 86, 102, 190, 110, 116) size 3613\n",
      "num de blobs predicted:  2\n",
      "prediction bbox (99, 8, 174, 207, 36, 187) size 13319\n",
      "True Positive:  False\n",
      "Scores post    : 0.0\n",
      "Haus post 1 class: 109.94920317359961\n",
      "TP:  0 FN:  3613.0 FP:  15777\n",
      "Px:  0442524\n",
      "num de blobs in label:  1\n",
      "label bbox  (42, 46, 132, 73, 78, 147) size 5864\n",
      "num de blobs predicted:  1\n",
      "prediction bbox (44, 96, 132, 70, 125, 147) size 5009\n",
      "True Positive:  False\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_pred and y should have same shapes, got torch.Size([1, 287, 288, 192]) and (1, 287, 192, 192).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 133\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# compute metric for current iteration\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metrics:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m#DICE\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mdice_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_blobn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_label\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#[0][1:2, :, :, :] [0]\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     dice1 \u001b[38;5;241m=\u001b[39m dice_metric\u001b[38;5;241m.\u001b[39maggregate()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScores post    :\u001b[39m\u001b[38;5;124m'\u001b[39m, dice1)\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/metrics/metric.py:329\u001b[0m, in \u001b[0;36mCumulativeIterationMetric.__call__\u001b[0;34m(self, y_pred, y)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_pred: TensorOrList, y: Optional[TensorOrList] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    Execute basic computation for model prediction and ground truth.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m    It can support  both `list of channel-first Tensor` and `batch-first Tensor`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m        The computed metric values at the iteration level.\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;241m*\u001b[39mret)\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/metrics/metric.py:72\u001b[0m, in \u001b[0;36mIterationMetric.__call__\u001b[0;34m(self, y_pred, y)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y_pred, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     71\u001b[0m     y_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred or y must be a list/tuple of `channel-first` Tensors or a `batch-first` Tensor.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/metrics/meandice.py:83\u001b[0m, in \u001b[0;36mDiceMetric._compute_tensor\u001b[0;34m(self, y_pred, y)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred should have at least 3 dimensions (batch, channel, spatial), got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# compute dice (BxC) for each channel for each batch\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute_meandice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_background\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_background\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_empty\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/metrics/meandice.py:138\u001b[0m, in \u001b[0;36mcompute_meandice\u001b[0;34m(y_pred, y, include_background, ignore_empty)\u001b[0m\n\u001b[1;32m    135\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred and y should have same shapes, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# reducing only spatial dimensions (not batch nor channels)\u001b[39;00m\n\u001b[1;32m    141\u001b[0m n_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_pred\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: y_pred and y should have same shapes, got torch.Size([1, 287, 288, 192]) and (1, 287, 192, 192)."
     ]
    }
   ],
   "source": [
    "##TESTING\n",
    "#Define PostTranforms\n",
    "out_channels = 2  # including background\n",
    "post_transforms = Compose(\n",
    "    [\n",
    "        EnsureType(),\n",
    "        AsDiscrete(argmax=True, threshold=0.1),\n",
    "        #FillHoles(applied_labels=1, connectivity=0),\n",
    "        #RemoveSmallObjects(min_size=64, connectivity=3, independent_channels=True),\n",
    "        ScaleIntensity(minv=0.0, maxv=1.0),\n",
    "        KeepLargestConnectedComponent(applied_labels=None,is_onehot=False,connectivity=2,num_components=1),\n",
    "        ResizeWithPadOrCrop(spatial_size=(288,288,192),method=\"symmetric\")\n",
    "    ]\n",
    ")\n",
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, threshold=0.1),\n",
    "                     ScaleIntensity(minv=0.0, maxv=1.0)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(threshold=0.5)],ResizeWithPadOrCrop(spatial_size=(288,288,192),method=\"symmetric\"))\n",
    "\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "hausdorff_metric = HausdorffDistanceMetric(include_background=False, reduction=\"mean\", percentile=95)\n",
    "surfDice_metric191 = SurfaceDiceMetric(class_thresholds=np.linspace(3, 3, 191), include_background=False)\n",
    "surfDice_metric287 = SurfaceDiceMetric(class_thresholds=np.linspace(3,3,287), include_background=False)\n",
    "surfDice_metric383 = SurfaceDiceMetric(class_thresholds=np.linspace(3, 3, 383), include_background=False)\n",
    "\n",
    "\n",
    "# Testing the model\n",
    "sumTP=0\n",
    "sumFN=0\n",
    "sumFP=0\n",
    "\n",
    "sum_voxTP=0\n",
    "sum_voxFN=0\n",
    "sum_voxFP=0\n",
    "\n",
    "ListTP=[]\n",
    "ListFN=[]\n",
    "ListFP=[]\n",
    "\n",
    "metrics=True\n",
    "full_volume_disp = True\n",
    "\n",
    "count = 0\n",
    "nr_images = 8\n",
    "rows=3\n",
    "figsize = (18, 9)\n",
    "all_metrics = []\n",
    "figs = False #Show and save Figures\n",
    "print(len(val_loader))\n",
    "modelSwin.eval()\n",
    "modelDyn.eval()\n",
    "with torch.no_grad():\n",
    "    for val_data in val_loader:\n",
    "        voxTP = 0\n",
    "        voxFN = 0\n",
    "        voxFP = 0\n",
    "\n",
    "        val_inputs, val_labels = (\n",
    "            val_data[\"image\"].to(device),\n",
    "            val_data[\"label\"].to(device),)\n",
    "        roi_size = image_size\n",
    "        sw_batch_size = 1\n",
    "        px = val_data[\"image\"].to('cpu').meta[\"filename_or_obj\"][0].split('/')[-2]\n",
    "        print('Px: ', px)\n",
    "\n",
    "        val_outputs_Swin = sliding_window_inference(val_inputs, roi_size, sw_batch_size, modelSwin)\n",
    "        val_outPost_Swin = [post_transforms(i) for i in decollate_batch(val_outputs_Swin)]\n",
    "\n",
    "        val_outputs_Dyn = sliding_window_inference(val_inputs, roi_size, sw_batch_size, modelDyn)\n",
    "        val_outPost_Dyn = [post_transforms(i) for i in decollate_batch(val_outputs_Dyn)]\n",
    "        \n",
    "\n",
    "        val_outPost = torch.logical_or(val_outPost_Swin[0], val_outPost_Dyn[0])\n",
    "            \n",
    "        image = val_inputs[0].detach().cpu().numpy()\n",
    "        image = image.squeeze()\n",
    "        \n",
    "        val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "        lbl_3dnp = val_labels[0].detach().cpu().numpy()\n",
    "        lbl_3dnp = lbl_3dnp.squeeze()\n",
    "        lbl_3dnp = dilation(lbl_3dnp, ball(2))\n",
    "        lbl_4d = np.expand_dims(lbl_3dnp, 0)\n",
    "        tensor_label = val_labels[0].detach().cpu()#torch.from_numpy(lbl_4d)\n",
    "        \n",
    "        label_img = label(lbl_3dnp)\n",
    "        regions = regionprops(label_img)\n",
    "        \n",
    "        print(\"num de blobs in label: \",len(regions))\n",
    "        for i in range(len(regions)):\n",
    "            r = regions[i]\n",
    "            attrs = [a for a in r.__dir__() if not a.startswith('_')]\n",
    "            print('label bbox ',r.bbox,\"size\",len(r.coords))\n",
    "            lbl_bbox = r.bbox\n",
    "                \n",
    "        out_3dnp = val_outPost[0].detach().cpu().numpy()\n",
    "        out_3dnp = out_3dnp.squeeze()\n",
    "        out_3dnp = dilation(out_3dnp, ball(2))\n",
    "\n",
    "        label_out_3dnp = label(out_3dnp)\n",
    "        props = regionprops(label_out_3dnp)\n",
    "\n",
    "        print(\"num de blobs predicted: \",len(props))\n",
    "        for n in range(len(props)):\n",
    "            r = props[n]\n",
    "            attrs = [a for a in r.__dir__() if not a.startswith('_')]\n",
    "            print('prediction bbox',r.bbox,\"size\",len(r.coords))\n",
    "            \n",
    "            patch = np.zeros(out_3dnp.shape)\n",
    "            for j in range(len(r.coords)): \n",
    "                patch[r.coords[j][0],r.coords[j][1],r.coords[j][2]]=1\n",
    "\n",
    "            TP = False\n",
    "            for j in range(len(r.coords)):\n",
    "                if (r.coords[j][0]>lbl_bbox[0] and r.coords[j][0]<lbl_bbox[3]) and(r.coords[j][1]>lbl_bbox[1] and r.coords[j][1]<lbl_bbox[4]) and (r.coords[j][2]>lbl_bbox[2] and r.coords[j][2]<lbl_bbox[5]):\n",
    "                    TP=True\n",
    "                    voxTP+=1\n",
    "            \n",
    "            #Create different matrixes, one for each blob to send to metrics\n",
    "            predicted_blobn = np.zeros(out_3dnp.shape)  \n",
    "            predicted_blobn[label_out_3dnp==n+1]=1\n",
    "            predicted_blobn = np.expand_dims(predicted_blobn, 0)\n",
    "            tensor_blobn = torch.from_numpy(predicted_blobn)\n",
    "                        \n",
    "            sumPredicted =np.sum(out_3dnp)\n",
    "            sumGroundT=np.sum(lbl_3dnp)\n",
    "            voxFP=sumPredicted-voxTP\n",
    "            voxFN=sumGroundT-voxTP\n",
    "            \n",
    "            print('True Positive: ',TP)\n",
    "            \n",
    "            # compute metric for current iteration\n",
    "            if metrics:\n",
    "                #DICE\n",
    "                dice_metric(y_pred=tensor_blobn, y=tensor_label) #[0][1:2, :, :, :] [0]\n",
    "                dice1 = dice_metric.aggregate().item()\n",
    "                print('Scores post    :', dice1)\n",
    "                dice_metric.reset()\n",
    "\n",
    "                hausdorff_metric(y_pred=tensor_blobn, y=tensor_label)\n",
    "                hausd1 = hausdorff_metric.aggregate().item()\n",
    "                hausdorff_metric.reset()\n",
    "                print('Haus post 1 class:', hausd1)\n",
    "                \n",
    "                #surfDice_metric(y_pred=tensor_blobn, y=tensor_label)\n",
    "                #sdice1 = surfDice_metric.aggregate().item()\n",
    "                #print('SurfFice post 1 class:', sdice1)\n",
    "\n",
    "            if TP:\n",
    "                sumTP = sumTP+1\n",
    "                ListTP.append(px)\n",
    "            if not(TP):\n",
    "                sumFN = sumFN+1\n",
    "                ListFN.append(px)\n",
    "            if len(props)>1:\n",
    "                sumFP = sumFP+1\n",
    "                ListFP.append(px)\n",
    "            \n",
    "            print('TP: ',voxTP,'FN: ',voxFN,'FP: ',voxFP)\n",
    "            break\n",
    "             #Plot all images\n",
    "            if full_volume_disp:\n",
    "                count=0\n",
    "                for i in range(lbl_3dnp.shape[2]):\n",
    "                    if (np.sum(lbl_3dnp[:, :,i],)>0) or (np.sum(patch[:, :,i],)>0):\n",
    "                        fig = plt.figure('Instance = {}'.format(0), figsize=figsize)\n",
    "                        ax = fig.add_subplot(121)\n",
    "                        ax.imshow(np.rot90(image[:, :, i]),cmap='gray'),plt.axis('off')\n",
    "                        ax = fig.add_subplot(122)\n",
    "                        ax.imshow(np.rot90(image[:, :, i]),cmap='gray'),plt.axis('off')\n",
    "                        ax.contour(np.rot90(lbl_3dnp[:,:,i]),colors='yellow')\n",
    "                        ax.contour(np.rot90(patch[:, :,i]),colors='red')\n",
    "                        ax.contour(np.rot90(out_3dnp[:, :,i]),colors='blue')\n",
    "                        ax.text(8, 10, 'Yellow Label', style='normal',color='white',fontsize=15)\n",
    "                        ax.text(8, 25, 'Blue Prediction', style='normal',color='white',fontsize=15)\n",
    "                        ax.text(8, 40, 'Red Patch', style='normal',color='white',fontsize=15)\n",
    "                        #plt.show()\n",
    "\n",
    "                        if not os.path.exists(os.path.join(figures_folder_i, px)):\n",
    "                            os.makedirs(os.path.join(figures_folder_i, px))\n",
    "\n",
    "                        plt.savefig(os.path.join(figures_folder_i, px, 'FullV_final_V10{}.png'.format(i)))\n",
    "\n",
    "            sum_voxTP+=voxTP\n",
    "            sum_voxFN+=voxFN\n",
    "            sum_voxFP+=voxFP\n",
    "\n",
    "        \n",
    "print(\"Sensitivity: \",sumTP/(sumTP+sumFN))\n",
    "print(\"Precision: \",sumTP/(sumTP+sumFP))\n",
    "\n",
    "print(sumTP,sumFN,sumFP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6afe089",
   "metadata": {},
   "outputs": [],
   "source": [
    "Px:  0442524\n",
    "num de blobs in label:  1\n",
    "label bbox  (42, 46, 132, 73, 78, 147) size 5864\n",
    "num de blobs predicted:  1\n",
    "prediction bbox (44, 48, 132, 70, 77, 147) size 5009\n",
    "True Positive:  True\n",
    "Scores post    : 0.7164799571037292\n",
    "Haus post 1 class: 2.0866646363185435\n",
    "TP:  4975 FN:  889.0 FP:  34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2889b6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73189710",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071502d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
