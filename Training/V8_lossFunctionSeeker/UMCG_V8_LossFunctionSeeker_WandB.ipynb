{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2331206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.ndimage import rotate\n",
    "import csv\n",
    "import SimpleITK as sitk\n",
    "#from lungtumormask import mask as tumormask\n",
    "#from lungmask import mask as lungmask_fun\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    RandFlipd,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    KeepLargestConnectedComponent,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    CenterSpatialCropd,\n",
    "    SpatialCropd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    AsDiscrete,\n",
    "    SpatialCrop,\n",
    "    RandSpatialCropd,\n",
    "    SpatialPadd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Invertd,\n",
    "    DivisiblePadd,\n",
    "    MapTransform,\n",
    "    HistogramNormalized,\n",
    "    ToTensord,\n",
    "    Transpose,\n",
    "    ToTensor,\n",
    ")\n",
    "from monai.optimizers import LearningRateFinder\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet,VNet,SwinUNETR,UNETR,DynUNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric,SurfaceDiceMetric,SurfaceDistanceMetric,HausdorffDistanceMetric\n",
    "from monai.losses import DiceLoss,DiceCELoss,MaskedDiceLoss,DiceFocalLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch,pad_list_data_collate\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01d0ce36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('device:', device)\n",
    "    num_workers=0#12\n",
    "\n",
    "    if True:\n",
    "        %matplotlib inline\n",
    "        \n",
    "    main():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7aa3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dd095e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LookSortFiles(all_patientdir):\n",
    "    CT_fpaths = []\n",
    "    lbl_fpaths= []\n",
    "    lung_fpaths = []\n",
    "    for patient_path in all_patientdir:\n",
    "        ct_miss = True\n",
    "        gtv_miss = True\n",
    "        lung_miss = True\n",
    "        for root, dirs, files in os.walk(root_path+patient_path, topdown=False):\n",
    "            for f in files:\n",
    "                if True:#NBIA database\n",
    "                    if \"_ct.nii.gz\" in f.lower() and ct_miss:\n",
    "                        CT_fpaths.append(os.path.join(root_path,patient_path,f))\n",
    "                        ct_miss = False\n",
    "                    if \"gtv-1.nii.gz\" in f.lower():\n",
    "                        lbl_fpaths.append(os.path.join(root_path,patient_path,f))\n",
    "                        gtv_miss =False\n",
    "                    if '_lungmask.nii.gz' in f.lower():\n",
    "                        lung_fpaths.append(os.path.join(root_path,patient_path,f))\n",
    "                        lung_miss = False\n",
    "\n",
    "                if \"50%_ct.nii.gz\" in f.lower() and ct_miss:\n",
    "                    CT_fpaths.append(os.path.join(root_path,patient_path,f))\n",
    "                    ct_miss = False\n",
    "                if \"rtstruct_gtv.nii.gz\" in f.lower():\n",
    "                    lbl_fpaths.append(os.path.join(root_path,patient_path,f))\n",
    "                    gtv_miss =False\n",
    "                if '50%_lungmask.nii.gz' in f.lower():\n",
    "                    lung_fpaths.append(os.path.join(root_path,patient_path,f))\n",
    "                    lung_miss = False\n",
    "            if ct_miss:\n",
    "                for f in files:\n",
    "                    if \"ex_ct.nii.gz\" in f.lower() and ct_miss:\n",
    "                        CT_fpaths.append(os.path.join(root_path,patient_path,f))\n",
    "                        ct_miss = False\n",
    "                    if 'ex_lungmask.nii.gz' in f.lower() and lung_miss:\n",
    "                            lung_fpaths.append(os.path.join(root_path,patient_path,f))\n",
    "                            lung_miss = False\n",
    "            if gtv_miss and not(ct_miss):\n",
    "                CT_fpaths.pop()\n",
    "            if gtv_miss and not(lung_miss):\n",
    "                lung_fpaths.pop()\n",
    "            if not(gtv_miss) and (ct_miss):\n",
    "                print(root)\n",
    "                for f in files:\n",
    "                    if \"mar_ct.nii.gz\" in f.lower() and ct_miss:\n",
    "                        CT_fpaths.append(os.path.join(root_path,patient_path,f))\n",
    "                        ct_miss = False\n",
    "                    if \"in_ct.nii.gz\" in f.lower() and ct_miss:\n",
    "                        CT_fpaths.append(os.path.join(root_path,patient_path,f))\n",
    "                        ct_miss = False\n",
    "                    if 'mar_lungmask.nii.gz' in f.lower() and lung_miss:\n",
    "                        lung_fpaths.append(os.path.join(root_path,patient_path,f))\n",
    "                        lung_miss = False\n",
    "                    if 'in_lungmask.nii.gz' in f.lower() and lung_miss:\n",
    "                        lung_fpaths.append(os.path.join(root_path,patient_path,f))\n",
    "                        lung_miss = False\n",
    "\n",
    "\n",
    "    print(len(CT_fpaths),len(lbl_fpaths),len(lung_fpaths))\n",
    "    CT_fpaths.sort()\n",
    "    lbl_fpaths.sort()\n",
    "    lung_fpaths.sort()\n",
    "\n",
    "    print(CT_fpaths[44])\n",
    "    print(lbl_fpaths[44])\n",
    "    print(lung_fpaths[44])\n",
    "    \n",
    "    return CT_fpaths,lbl_fpaths,lung_fpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98b93981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307\n"
     ]
    }
   ],
   "source": [
    "def main():    \n",
    "    #peregrine\n",
    "    #root_path = '/data/p308104/NBIA_Data/NIFTI_NBIA/imagesTr/'\n",
    "    #root_path = '/data/p308104/Nifti_Imgs_V0/' #UMCG data on peregrine\n",
    "    #root_path = '/data/p308104/MultipleBP/'\n",
    "    #local\n",
    "    root_path = '/home/umcg/Desktop/NBIA/NBIA_Nifti_v0/'\n",
    "    #root_path = '/home/umcg/Desktop/Dicom_UMCG/MultipleBP/' \n",
    "    #root_path = '/home/umcg/OneDrive/MultipleBreathingP/'\n",
    "    #root_path = '/home/umcg/Desktop/AutomaticITV_code/MultipleBreathingP-OneDriveCopy/MultipleBreathingP/'\n",
    "    all_patientdir = []\n",
    "    all_patientdir = os.listdir(root_path)\n",
    "    all_patientdir.sort()\n",
    "    print(len(all_patientdir))\n",
    "\n",
    "    CT_fpaths,lbl_fpaths,lung_fpaths = LookSortFiles(all_patientdir)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ad75fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train val len: 17 - 5\n"
     ]
    }
   ],
   "source": [
    "#Create data dictionat\n",
    "data_dicts = [\n",
    "    {\"image\": image_name,\"lung\":lung_name,\"label\": label_name}\n",
    "    for image_name,lung_name,label_name in zip(CT_fpaths,lung_fpaths,lbl_fpaths)\n",
    "]\n",
    "train_files, val_files = data_dicts[:-290], data_dicts[-5:]\n",
    "print('train val len:',len(train_files),'-',len(val_files))\n",
    "\n",
    "minmin_CT = -1024 #NBIA\n",
    "maxmax_CT = 3071 #NBIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa5cd60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to transpose lung mask\n",
    "class Create_sequences(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__(keys)        \n",
    "        print(f\"keys to transpose: {self.keys}\")\n",
    "     \n",
    "    def __call__(self, dictionary):\n",
    "        dictionary = dict(dictionary)\n",
    "        for key in self.keys:\n",
    "            data = dictionary[key]\n",
    "            if key == 'lung':\n",
    "                data = np.transpose(data, (0,2,3,1))\n",
    "                data = rotate(data,270,axes=(1,2),reshape=False)\n",
    "                data = np.flip(data,1)\n",
    "                data[data==2] = int(1)\n",
    "                data[data!=1] = int(0)\n",
    "            dictionary[key] = data\n",
    "            \n",
    "        return dictionary        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eff5068a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys to transpose: ('image', 'lung', 'label')\n",
      "keys to transpose: ('image', 'lung', 'label')\n"
     ]
    }
   ],
   "source": [
    "#Create Compose functions for preprocessing of train and validation\n",
    "set_determinism(seed=0)\n",
    "image_keys = [\"image\",\"lung\",\"label\"]\n",
    "p = .5 #Data aug transform probability\n",
    "size = 64#96\n",
    "image_size = (size,size,size)\n",
    "pin_memory = True if num_workers > 0 else False  # Do not change \n",
    "\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=image_keys),\n",
    "        EnsureChannelFirstd(keys=image_keys),\n",
    "        Orientationd(keys=[\"image\",\"label\"], axcodes=\"RAS\"),\n",
    "        #Spacingd(keys=[\"image\",\"label\"], pixdim=(1,1,1),mode=(\"bilinear\",\"nearest\")),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=minmin_CT, a_max=maxmax_CT,b_min=0.0, b_max=1.0, clip=True,),\n",
    "        Create_sequences(keys=image_keys),\n",
    "        CropForegroundd(keys=image_keys, source_key=\"lung\",k_divisible = size),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=image_keys,label_key='label',spatial_size=image_size,pos=1,neg=1,num_samples=2,\n",
    "            image_key='image',image_threshold=0,),\n",
    "        ToTensord(keys=image_keys),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=image_keys),\n",
    "        EnsureChannelFirstd(keys=image_keys),\n",
    "        Orientationd(keys=[\"image\",\"label\"], axcodes=\"RAS\"),\n",
    "        #Spacingd(keys=[\"image\",\"label\"], pixdim=(1,1,1),mode=(\"bilinear\",\"nearest\")),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=minmin_CT, a_max=maxmax_CT,b_min=0.0, b_max=1.0, clip=True,),\n",
    "        Create_sequences(keys=image_keys),\n",
    "        CropForegroundd(keys=image_keys, source_key=\"lung\",k_divisible = size),\n",
    "        ToTensord(keys=image_keys),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9640b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the images after the preprocessing\n",
    "#Check the images after the preprocessing\n",
    "if False:\n",
    "    train_ds = CacheDataset(data=train_files, transform=train_transforms,cache_rate=1.0,num_workers=num_workers)\n",
    "    train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "    val_ds = CacheDataset(data=val_files, transform=val_transforms,cache_rate=1.0,num_workers=int(num_workers//2))\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=int(num_workers//2),pin_memory=pin_memory)\n",
    "if True:\n",
    "    train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "    train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "    val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=0)#,collate_fn=pad_list_data_collate)\n",
    "    \n",
    "if False:\n",
    "    check_ds =CacheDataset(data=train_files, transform=train_transforms,cache_rate=1.0,num_workers=num_workers)\n",
    "    check_loader = DataLoader(check_ds, batch_size=1,num_workers=num_workers)\n",
    "    \n",
    "if False: #Normal dataset not Cache\n",
    "    check_ds =Dataset(data=train_files, transform=train_transforms)\n",
    "    check_loader = DataLoader(check_ds, batch_size=1,num_workers=0)\n",
    "    if True:\n",
    "        count = 1\n",
    "        for batch_data in check_loader:\n",
    "            #batch_data = first(check_loader)\n",
    "            image,lung, label = (batch_data[\"image\"][0][0],batch_data[\"lung\"][0][0],batch_data[\"label\"][0][0])\n",
    "            print(f\"px info:{count },image shape: {image.shape},lung shape: {lung.shape}, label shape: {label.shape}\")\n",
    "            count+=1\n",
    "            for i in range(label.shape[2]):\n",
    "                if torch.sum(label[:,:,i])>0:\n",
    "                    plt.subplot(2,3,1),plt.imshow(image[:,:,i]),plt.axis('off')\n",
    "                    plt.subplot(2,3,2),plt.imshow(label[:,:,i]),plt.axis('off')\n",
    "                    plt.subplot(2,3,3),plt.imshow(label[:,:,i]+image[:,:,i]),plt.axis('off')\n",
    "                    plt.subplot(2,3,4),plt.imshow(image[:,:,i+2]),plt.axis('off')\n",
    "                    plt.subplot(2,3,5),plt.imshow(label[:,:,i+2]),plt.axis('off')\n",
    "                    plt.subplot(2,3,6),plt.imshow(label[:,:,i+2]+image[:,:,i]),plt.axis('off')\n",
    "                    plt.tight_layout(),plt.show()\n",
    "                    break\n",
    "            if count>10:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "883236bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model\n",
    "spatial_dims = 3\n",
    "max_epochs = 100\n",
    "in_channels = 1\n",
    "out_channels=2 #including background\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-5\n",
    "T_0 = 40  # Cosine scheduler\n",
    "\n",
    "model = SwinUNETR(\n",
    "    image_size, \n",
    "    in_channels, out_channels, \n",
    "    use_checkpoint=True, \n",
    "    feature_size=24,\n",
    "    #spatial_dims=spatial_dims\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb702f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "pretrained_path = None\n",
    "#pretrained_path = '/home/umcg/Desktop/AutomaticITV_code/weights/best_m_MONAI_V3_NBIAWeightsretrainedWithUMCGdata.pth'\n",
    "#weights_name = 'best_m_MONAI_V3_UMCGWeightsretrainedWithUMCGdata_X2RetrainedwithAITVdata.pth'\n",
    "#pretrained_path = '/data/p308104/MultipleBP/'+weights_name\n",
    "if pretrained_path is not(None):\n",
    "    model.load_state_dict(torch.load(pretrained_path, map_location=torch.device(device)))\n",
    "\n",
    "    #weight = torch.load(pretrained_path, map_location=torch.device(device))\n",
    "    #model.load_from(weights=weight)\n",
    "    print('Using pretrained weights!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d6226ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "lf_select =0\n",
    "#params\n",
    "def Loss_functionsSelector(loss_fold):\n",
    "    if loss_fold==0:\n",
    "        SelectedLoss = DiceLoss(include_background=False,to_onehot_y=True, sigmoid=True)\n",
    "    if loss_fold==1:        \n",
    "        SelectedLoss = MaskedDiceLoss(include_background=False,to_onehot_y=True, sigmoid=True)\n",
    "    if loss_fold==2:\n",
    "        SelectedLoss = DiceCELoss(include_background=False,to_onehot_y=True, sigmoid=True)\n",
    "    if loss_fold==3:\n",
    "        SelectedLoss = DiceFocalLoss(include_background=False,to_onehot_y=True, sigmoid=True)\n",
    "    return SelectedLoss\n",
    "\n",
    "#learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=T_0,\n",
    "                                                                     T_mult=1, eta_min=1e-8)\n",
    "\n",
    "#metrics\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\",get_not_nans=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b22e9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True,threshold=0.5)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(threshold=0.5)],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eeab00d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/umcg/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c50edce61504cb5bb25acc23611a3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016672014049997113, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Failed to sample metric: Not Supported\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/umcg/Desktop/AutomaticITV_code/wandb/run-20221114_145423-2oiyo39t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ldelaoa/NBIA_V0/runs/2oiyo39t\" target=\"_blank\">crimson-lion-4</a></strong> to <a href=\"https://wandb.ai/ldelaoa/NBIA_V0\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"NBIA_V0\", entity=\"ldelaoa\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 100,\n",
    "  \"batch_size\": 128,\n",
    "  \"loss function\":Loss_functionsSelector(lf_select)\n",
    "}\n",
    "\n",
    "wandb.watch(model, log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22411428",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "epoch 1/100\n",
      "1/8, train_loss: 0.8035\n",
      "2/8, train_loss: 0.9493\n",
      "3/8, train_loss: 0.9187\n",
      "4/8, train_loss: 0.7861\n",
      "5/8, train_loss: 0.9399\n",
      "6/8, train_loss: 0.9936\n",
      "7/8, train_loss: 0.8908\n",
      "8/8, train_loss: 0.8945\n",
      "9/8, train_loss: 1.0000\n",
      "epoch 1 average loss: 0.9085\n",
      "------------------------------------------------------------\n",
      "epoch 2/100\n",
      "1/8, train_loss: 0.8300\n",
      "2/8, train_loss: 0.9404\n",
      "3/8, train_loss: 0.9188\n",
      "4/8, train_loss: 0.9654\n",
      "5/8, train_loss: 0.8286\n",
      "6/8, train_loss: 0.9292\n",
      "7/8, train_loss: 0.9667\n",
      "8/8, train_loss: 0.8803\n",
      "9/8, train_loss: 0.9976\n",
      "epoch 2 average loss: 0.9174\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.0201\n",
      "best mean dice: 0.0201 at epoch: 2\n",
      "------------------------------------------------------------\n",
      "epoch 3/100\n",
      "1/8, train_loss: 0.9831\n",
      "2/8, train_loss: 0.7536\n",
      "3/8, train_loss: 0.8795\n",
      "4/8, train_loss: 0.9205\n",
      "5/8, train_loss: 0.7592\n",
      "6/8, train_loss: 0.8560\n",
      "7/8, train_loss: 0.7100\n",
      "8/8, train_loss: 1.0000\n",
      "9/8, train_loss: 0.6551\n",
      "epoch 3 average loss: 0.8352\n",
      "------------------------------------------------------------\n",
      "epoch 4/100\n",
      "1/8, train_loss: 0.9171\n",
      "2/8, train_loss: 0.9297\n",
      "3/8, train_loss: 0.9801\n",
      "4/8, train_loss: 0.9754\n",
      "5/8, train_loss: 0.6579\n",
      "6/8, train_loss: 0.8720\n",
      "7/8, train_loss: 0.9010\n",
      "8/8, train_loss: 0.8683\n",
      "9/8, train_loss: 1.0000\n",
      "epoch 4 average loss: 0.9002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m roi_size \u001b[38;5;241m=\u001b[39m image_size\n\u001b[1;32m     53\u001b[0m sw_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 54\u001b[0m val_outputs \u001b[38;5;241m=\u001b[39m \u001b[43msliding_window_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroi_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msw_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m val_outputs \u001b[38;5;241m=\u001b[39m [post_pred(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m decollate_batch(val_outputs)]\n\u001b[1;32m     56\u001b[0m val_labels \u001b[38;5;241m=\u001b[39m [post_label(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m decollate_batch(val_labels)]\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/inferers/utils.py:180\u001b[0m, in \u001b[0;36msliding_window_inference\u001b[0;34m(inputs, roi_size, sw_batch_size, predictor, overlap, mode, sigma_scale, padding_mode, cval, sw_device, device, progress, roi_weight_map, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m unravel_slice \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    174\u001b[0m     [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28mint\u001b[39m(idx \u001b[38;5;241m/\u001b[39m num_win), \u001b[38;5;28mint\u001b[39m(idx \u001b[38;5;241m/\u001b[39m num_win) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(slices[idx \u001b[38;5;241m%\u001b[39m num_win])\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m slice_range\n\u001b[1;32m    176\u001b[0m ]\n\u001b[1;32m    177\u001b[0m window_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    178\u001b[0m     [convert_data_type(inputs[win_slice], torch\u001b[38;5;241m.\u001b[39mTensor)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m win_slice \u001b[38;5;129;01min\u001b[39;00m unravel_slice]\n\u001b[1;32m    179\u001b[0m )\u001b[38;5;241m.\u001b[39mto(sw_device)\n\u001b[0;32m--> 180\u001b[0m seg_prob_out \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# batched patch segmentation\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# convert seg_prob_out to tuple seg_prob_tuple, this does not allocate new memory.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m seg_prob_tuple: Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/networks/nets/swin_unetr.py:297\u001b[0m, in \u001b[0;36mSwinUNETR.forward\u001b[0;34m(self, x_in)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_in):\n\u001b[0;32m--> 297\u001b[0m     hidden_states_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswinViT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m     enc0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder1(x_in)\n\u001b[1;32m    299\u001b[0m     enc1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder2(hidden_states_out[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/networks/nets/swin_unetr.py:1018\u001b[0m, in \u001b[0;36mSwinTransformer.forward\u001b[0;34m(self, x, normalize)\u001b[0m\n\u001b[1;32m   1016\u001b[0m x3_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_out(x3, normalize)\n\u001b[1;32m   1017\u001b[0m x4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers4[\u001b[38;5;241m0\u001b[39m](x3\u001b[38;5;241m.\u001b[39mcontiguous())\n\u001b[0;32m-> 1018\u001b[0m x4_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [x0_out, x1_out, x2_out, x3_out, x4_out]\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/monai/networks/nets/swin_unetr.py:998\u001b[0m, in \u001b[0;36mSwinTransformer.proj_out\u001b[0;34m(self, x, normalize)\u001b[0m\n\u001b[1;32m    996\u001b[0m     n, ch, d, h, w \u001b[38;5;241m=\u001b[39m x_shape\n\u001b[1;32m    997\u001b[0m     x \u001b[38;5;241m=\u001b[39m rearrange(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn c d h w -> n d h w c\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 998\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    999\u001b[0m     x \u001b[38;5;241m=\u001b[39m rearrange(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn d h w c -> n c d h w\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x_shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/AutomaticITV_code/Aitv_envV0/lib/python3.10/site-packages/torch/nn/functional.py:2503\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2501\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2502\u001b[0m     )\n\u001b[0;32m-> 2503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metric_values = []\n",
    "nr_images = 8\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    train_num_iterations = len(train_loader)\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs,labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss_function=Loss_functionsSelector(lf_select)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        scheduler.step(epoch + (step / train_num_iterations))\n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
    "            f\"train_loss: {loss.item():.4f}\")\n",
    "        \n",
    "        \n",
    "        wandb.log({\"train/loss\": loss.item()})\n",
    "    \n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    wandb.log({\"train/loss_epoch\": epoch_loss})\n",
    "    wandb.log({\"learning_rate\": scheduler.get_lr()[0]})\n",
    "    \n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),)\n",
    "                roi_size = image_size\n",
    "                sw_batch_size = 1\n",
    "                val_outputs = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model)\n",
    "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "\n",
    "                #postImg_monai = [post_transforms(i) for i in decollate_batch(val_outputs)]\n",
    "\n",
    "                #compute metric for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                #dice_metric(y_pred=postImg_monai[0][1:2,:,:,:], y=val_labels[0])\n",
    "\n",
    "\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            metric_values.append(metric)\n",
    "            wandb.log({\"val/dice_metric\": metric})            \n",
    "            dice_metric.reset()\n",
    "\n",
    "\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(\n",
    "                    root_path, \"best_m_MONAI_V3_UMCGWeightsretrainedWithUMCGdata_X2RetrainedwithAITVdata.pth\"))\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "                f\"at epoch: {best_metric_epoch}\")\n",
    "\n",
    "            \n",
    "wandb.log({\"best_dice_metric\": best_metric, \"best_metric_epoch\": best_metric_epoch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470f2e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
